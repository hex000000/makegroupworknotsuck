# Methodology
## Using MAXQDA for a systematic scoping review

Using a Qualitative Data Analysis application along with a bibliographic database means that a single source set of data can be collected and categorised in a way that preserves the connection between bibliographic record and full text, while at the same time allowing both qualitiative and quantitative data analysis of document variables and user-added or automatic coding.

As the systematic aspect of the review should be replicable {Arksey, 2005 #7;Peters, 2015 #5}, keeping each set of documents separate during the early stages of the process allows repeat review. This is more likely in a scoping review as iterative refinement of protocol occurs {Peters, 2015 #5}, when the full range of data is not  initially known {Arksey, 2005 #7;Peters, 2015 #5}.

A full description of the search sequence and terms is available in the Literature Review Method chapter. All results were saved to source-specific EndNote Library. Where full-text was available, these were attached to the bibliographic record and the filename changed to consistently be author-year-title. This is important because in MAXQDA this is how you will identify the documents in the document list.

There are arguments to be made both for creating a coding system prior to importing documents to MAXQDA and for allowing codes to emerge from the content of the documents themselves. As I had begun the project with a different focus, I had a legacy code set that I did not remove. Its development was a thorough and deliberate endeavour and it will be useful in the broader, non-scoping, Literature Review.

While MAXQDA does allow import/export of documents, codes and variables, there are technical affordances in creating a blank project file, then saving a copy of this with the name of the data set you are about to import if you want to use a pre-determined coding system. However, for a scoping review, the codes may take several sets of documents to develop as different sources introduce new nuances that must be accommodated.

Like EndNote, MAXQDA does not recommend storing your project or associated files in a networked or cloud-linked folder such as Dropbox. This necessitates an organised approach to file and folder locations as both applications have dependencies and default behaviour that they prefer. I found it helpful to keep a list of the locations as I was transferring both sets of data between two computers. (Example at /Users/eb/Dropbox/Documents/-Fed/Termites-and-Butterflies/Documents/File_Locations.xlsx)

I decided that for each application, I would create a projects folder in the local computer's  Applications folder as the path on both Macs will be a stable location. For each EN and 2020, there is a titled folder in the Applications folder of each Mac, containing:
- the application
- necessary support files
- a sub-folder with option-f extension containing current project files.

Then, in Dropbox, for each applicaiton an an _Exchange folder, which contains the sub-folder, which will be copied from the current and to the next current device as needed, and back again.

### Workflow

1. Work on local machine, save Library/Project in specified folder.
1. Copy folder to an Exchange folder on Dropbox.
1. Copy folder from that Exchange folder to next local machine (the Plus version allows installation on two computers).
1. When finished, copy back to Exchange and repeat from step 1 on other computer

It's REALLY important to note that once documents (or videos, or audio) are imported to MAXQDA they can't be modified, only coded and annotated. Quality Assurance should be carried out at each stage to avoid multiple versions of a document with different details.

I began with the output from epistemonikos as it had a small number of files but more than one.

### EndNote preparation
1. Export results from database as .RIS
1. Import to EndNote (doesn't have to be a new Library at this point)
1. Check that all abstracts are in place in EndNote (so they come into MAXQDA, particularly important if no full-text)
1. Find full text if possible
1. Rename attachments author-date-titles
1. Copy the records to new library, eg <EN-epistemonikos.enl> (this ensures that the renamed PDFs are in a folder unique to this library - important for MAXQDA import later)
1. Select all documents and Export as .RIS (RefMan output option, will have a .txt extension on filename)

### MAXQDA import
1. Import to 2020. I didn't check the 'external' checkbox, so will they import to 2020 and do they just end up loose in the folder? They come in in two new folders "references" and references> attachments. I moved the PDFs into the RIS folder which I retitled epistemonikos.

The links work!





The next set of files to export from EN should be a small set, with procedure replicable as part of the SSR.


Then there are the books. I focused on the most recent volume of the most cited? Work by Fransella, Bay & Bannister.

One limitation of scoping reviews is that they do not provide an exhaustive and formal appraisal of evidence across the body of research {Arksey, 2005 #7}. This is a significant issue for health and medical research with randomised and controlled trials, but less problematic for this study, as any evaluative methods are likely to be highly variable and context-dependent. The systematic process of scoping is likely to be beneficial to our understanding of those evaluative methods and the situations in which they are found.

Persistent problems occurred with searching caused by cookie and adblocker issues. It was difficult to have effective privacy settings as well as save searches and set alerts. That meant I had to repeat several searches from the beginning, as what ever the problem was would only become clear when I tried to either save or set a search alert or export search results.

Now I am waiting for tech help, work on reducing the sets of files down to relevance.

First set, epistemonikos because the smallest, so a good way to

OK, have an idea to keep the PDFs in place. What about unchecking the "store in folder for external files"?

OK, so now it is leaving the PDFsin EN, which isn't bad, but it does mean they're inside the file, which IS bad. So there is nO way to keep then in EN. So now, will export to Blexternals.

Select PDFs in list, then Exernal Files > Store documents in folder for external files. But they are already "external files", in the EN location. I think it's the Saving As that is embedding the files.YES!!!! THAT'S THE PROBLEM!!!!!

I've sorted that out :-|

So now i have to gently replace the Arksey paper somehow.
Used  Teamwork> Teamwork Export: Data Exchange file write to create an exchange file with the two documents (RIS & PDF).
Opened M-Method 2020 and then...  Teamwork> Teamwork Import: reading from Exchange file data. It asked whether I wanted to import the RIS as new, so uncheck that box, andit looks like it recognises the PDFas the name is identical.

With heart in mouth, I click Next, it confirms 22 codes and 8 coded segments. Next. Overwrite existing segment boundaries with imported ones? yes. Other options are inner bounds, outer bounds and keep existing. 52 variables? not sure that I might want to delete those. Import.

Automatically creates a backup prior to Merge.

YEAH BABY!!! I've nailed it. So considerations:

a. Saving a copy duplicates the PDFs internally
b. When I want to bring in a new RIS containing previously coded PDFs, I can use the Export / Import to retain the coding.

OK.

Always start with an empty project file saved as the name of the import you're about to do so the PDFs don't get duplicated. Because I've been working on a version that included the original RIS DUMMY field.

Two more Shaw to come in, coded before I did the systematic thing, definitely in the YES set. Interactive came through alright, might need to adjust the thesis filename. Tried this, didn't automatically find target so manually set a target.

#LEGEND
summary: save project as makes all files internal

epistemoff.2020.

From a surface perspective, all the articles are about people in some kind of therapeutic engagement. For me, this is what i categorise as "clinical". I'm reviewing these articles further in 2020 to see which terms I should exclude from the next phase of search strategy.

While 2020 can't do Word Clouds from PDFs, you can select the PDF text and create a document from it, which can then be turned into a word cloud.

So systematically going through epistemonikos... Some PDFs are not textable. What if I modify the original pDF? Doesn't work. So need to run OCR on everything before import. Already done with CPSC. Only a couple of epistemonikos are images.

All text captured from article individually, then individual word clouds, qord frequencies and a consoldiated version to test stoplist words and exclusions. Current stoplist is at https://www.dropbox.com/sh/c17n3w17be32tsn/AACtCqpK-0JBpz4yomBFzkSla?dl=0.

I did have a set of gowords from prewious studies but I think i need to generate a research-led pne.
By row 100 in the all-epistemoniks the terms were starting to repeat with minor variations. New tab in spreadsheet https://www.dropbox.com/s/3mcz0w21l0ttvex/updated-stoplist-analysis.xlsx?dl=0 with discussion.

New stoplists uploaded: PCP-sometimes.txt
other-1118.txt
numbers.txt
clinical.txt

These can be used to reduce quantity of results in other searches.
Now another word cloud of the epistemonikos.
Showed that the stop lists didn't necessarily stop the words. So now I will go through and manually remove them from the frequ dialog in 2020. After manually adding those identified to the stop list, another frequency list and word cloud were created. Searching the frequency list for "education" returned five results - I need to output these with commentary tomorrow :-)

I am going to use 2020 to analyse those five results as a test base for the next set of records. I have already saved all the epistemonikos PDFs as text to do the word cloud and stop word analysis.

## Search Procedure:
1. Select all the documents
1. Click the magnifying glass. Nup.
1. Enter educat* (2020 searches for it appearing anywhere within the word). That didn't do anything.
Now trying the "Lexical Search" function from the Analysis tab.
Searched for "educat".
18 results. 9 in the text documents, and 9 in the PDFs. So I only have to search the PDFs, which will make it easier to contextualise the reference.

well, it's not a perfect duplication - they are referrig to the same passsages in the same work, but the PDF version provides a longer context string - that may be a setting: /Volumes/eb/Dropbox/Documents/-Fed/Termites-and-Butterflies/Documents/0_Chapters-see GitHub-repgrid/images/Screen Shot 2019-11-21 at 6.31.05 pm.png.

For now, I select the PDF documents and activate them then run search in activated documents only. I now just have 9.
Clicking the blue lines next to the search results takes you to that place in the document.
I reviewed each instance o the search string and recorded results in an excel table that I need to convert for here: /Volumes/eb/Dropbox/Documents/-Fed/Termites-and-Butterflies/Data/Document-Reviews/M-epistemonikios-results.xlsx

I also selected all the documents and Auto-Coded them as NO-clinical, with the segments including one sentence before and one after (a setting in the AutoCode dialogue).

OK
Now I need to reduce the next batch of files using the stoplists, and search using that process.

Next, the Cochrane Library things & protocol.

1. Check abstracts and full texts are in EN T&B Library before exporting sub-library.
2. Export .ris from sub-library into properly named folder

1. Do I need to put them in 2020? it's clear from titles and abstracts they're all clinical except one which is about satiety.

Will put them in and re-think. One PDF wobbly, one not found, two duplicates. Downloaded a related study just for interest on a Quality of Life modelling that is done with RepGrid.

1. Open empty 2020 project, and save as <name matching EN export>.

1. Import bibliographic data - go to EN option and select folder and .RIS, choose import option but not the store option
1. Search educa (to disambiguate from reduc•)

Again, none suitable, but this is too slow.

Realised I should turn my stop lists into global stop lists. Also clear that counselling should be added to the list - added them to the clinical list. I'll add it to the blank sp it will apply to future 2020 projects.

Now reviewing is going to get harder, so I have to come up with some kind of search strategy. Biggest issue is going to be getting the full-text of thousands of papers.

What are my aims? to provide   benchmark of how RepGrid has been operationalised in education, preferably higher education. This is a descriptive endeavour, with more depth and synthesis of those studies found in HE in my complete Literature Revie.

OK. Next run is A+ Education. What's your plan? No point bringing into 2020 without th PDFS.
Realise I also need to add the multiple software packages & webpages at some point.
Not a single full-text found.

Narrow the search strategy.
educa* (avoiding the reduce trap) AND "repgrid" OR "repertory grid" BUT NOT words in the clinical stoplist OR child OR children. Screen snot  at /Volumes/eb/Dropbox/Documents/-Fed/Termites-and-Butterflies/Command Files/APlus-search_strategy.png

Result is 55 hits in 55 documents (remembering I only have abstracts here). Manual review of the 55 and then I'll have to find the PDFs of those that fit the parameters.

What are the parameters? Used in what Lina would call an epistemic activity (see notes) in research and practice conducted in higher education. (And these studies will be mostly Autralian because Aplus).

This time instead of exporting before I code them and manually noting, I will code first and then export.

Abstracts read thoroughly for alignment with parameters:
- educational setting (not clinical education, eg adherence to medication regimes)
AND
- epistemic focus (knowledge construction or co-construction, metacognition, problem-solving/decision-making - that is a tough distinction, tacit knowledge elicitation)
OR
- collaboration focus (model-building, decision-making)
OR
- research focus (educational researchers using repgrid as a survey instrument) - here "educational" is the tricky bit, because what about transformed sound and other good papers like that. Maybe it's a more nuanced breakdown into things that are hard to research with traditional instruments. So have a category for all those other non-clinical/psych/counselling research which is excluded, and another for other types of research, maybe separate out marketing later, then look within the other papers at types of research which have used the grid where other things don't work.

so does that mean I should look at those tags specifically? go back and look at the studies you've coded so far.

I need two levels of coding again, like with the Shaw & Gaines papers. One level solely for he SSR, and another for me. Do mine on the second pass after first chunking them in or out.

Coding at this time ignores relevance to me, just inclusion or not. Will re-code those already done as follows and update as we go.

| Setting                    | Epistemic Activities         | Research |                                          | Something Else           | Tools |
|----------------------------|------------------------------|----------|------------------------------------------|--------------------------|-------|
| Police Training            | Conceptual Mapping           | Survey   | prevailing discourses in police training | Interdisciplinary        |       |
| Employers & School Leavers | Teaching Tool need more info |          | design activities                        | Intercultural            |       |
| Teacher Education          | Team decision-making         |          | preferences                              | Focus on PCP             |       |
| Stakeholders               | Model Building               |          | personal characteristics                 | Professional Development |       |
| Unsure of level            | Collaboration skills         |          | thinking and behaviour                   |                          |       |
| Adult Ed                   | Leadership                   |          | experiences and perceptions              |                          |       |
| Other                      | Knowledge Elicitation        |          | relationships                            |                          |       |
| Market Research            | Decision-Making              |          | teamwork                                 |                          |       |
| Therapeutic                | Problem-Solving              |          | conceptual understanding                 |                          |       |
| Clinical                   | Metacognition                |          | assessment criteria                      |                          |       |
| School Ed                  | Knowledge Co/nstruction      |          |                                          |                          |       |
| Higher Ed                  |                              |          |                                          |                          |       |


Have made some changes to the code tree which I will update every now and again. Decided I would not separate TAFE and Higher Ed settings as there are enough common features - especially about survey research rather than teaching. Schools coded as such hen referred to as "school" in Abstract or keywords, Unsure codes will check to confirm.
Consider having some kind of Literacy code along with Inters. Maybe that can come out of text analysis.
OK realise I need to include in the survey section what the survey was about. Going back over the ten papers  now.

Need to go back and refine all those "student" teachers differently to non pre-service? Text analysis should help with that. Maybe just code them also as HE.

I think I also need to go back to tease out the 'classroom teaching' as there are a lot of those. Also need to add who was surveyed, teachers, students, stakeholders? No, HE means students unless it's also Teacher Ed.
I have put beliefs in with experiences and perceptions.
practice goes in with behaviour but might change code name
code table updated in /Applications/MAXQDA/MAXQDAƒ/APlus-code-plus-legacy.xlsx and main sheet at https://www.dropbox.com/s/1eiygm8w2ky89se/Termites-and-Butterflies.xlsm?dl=0

so what is my search plan, given the coding so far... see the T&B spreadhseet logic & strategy tabs

Narrow the search strategy.
educa* (avoiding the reduce trap) AND "repgrid" OR "repertory grid" BUT NOT words in the clinical stoplist OR child OR children. Screen snot  at /Volumes/eb/Dropbox/Documents/-Fed/Termites-and-Butterflies/Command Files/APlus-search_strategy.png

Re-run all prior searches to see if they fit, then re-code.
Identify new codes required.
Export codes from 2020, remove all the auto-assigned ones, keep only the Tools/Setting/Epistemic/Research/Something Else categories for now. Will see what coding S&G adds to this set.

1. Gaines & Shaw from RepPlus site - all 197 of them :-| Yess and Maybes already in, adding the Nos now. Should I use the same strategy? Run and test. Particularly beccause there are mostly pre-1980s conference papers so abstracts might be short. In A+, all I had was abstracts. I have all the full papers from G&S. I will search the papers rather than abstracts> Or do both and see what the difference is.

1. Search document system. Select, Analysis tab, Extended Lexical search, Open saved search called aPlus-ssearch.sea </Applications/MAXQDA/MAXQDAƒ/aPlus-search.sea> : all educa*; one "repertory grid" repgrid; none patient
patients
medication
medicine
medicines
clinical
clinician
depression
surgery
therapy
psychosis
psychoses
disease
pgi
schizophrenia
clinic
chronic
med
nr
recovery
depression
trial
counsel
counselling child children

32 hits in 32 documents and 3 document groups.
It searched both abstracts and PDFs. The 32 documents are listed in the RepPlus-searched tab of T&B.

Repeat trying RIS only: 6 Results'
Repeat PDF only expect 32 results - 26 hits 26 docs 3 groups.
Overlap?
Coped and pasted into sheet and then realised that the RIS only have author-year and not the document title. So a manual check of the PDF to which the RIS is linked. Activated all the RIS, repeat search, only one overlap. Probably stoplist kicking in.
Now manual check of those identified, and not identified, so see if search is accurate enough. Repat searches and make a set of each RIS, PDF and NotID.
Coded
- Lex-search-PDFs
- Lex-search-RIS

"Document variables, which display how often a code exists (their source is acknowledged as “code”) can be transformed into a binary variable by clicking on the  “COnvert to boolean variable” button. After it is transformed the variable will not show, how often a code has been assigned in the document, but if it has been assigned in this document or not."

Selected codes, right-click and   "Transform to document variable".
A column is added for each in the Data Editor window, with the number of codings as an integer.
In the Document Variables List, click the Categorical checkbox.
Click the Convert to Boolean button
Mixed Methods Tab, Activate documents by Variables
Conditions Lex-search-RIS=0 AND Lex-search-RIS=0 -> Creates a saved set
Also found on the Code More.. contextual menu an Invert Activation option.

But now activated, how do I apply a code to them?
Can I do it programmatically through a variable?
Repeat previous actions with Lex-search-NO
Can't use normal coding because no text selected in the Documents

In Data Editor for Document Variables, I can click each of the Lex codes in turn to sort by code. Clicking RIS, then PDF, then NO means that all the documents with the first two codes are at the top/bottom of the list. Can't also show only Activated documents.

Can't select multiple documents. Can't input as in the click the NO box manually. I think I will just have to leave it as a set for now. The purpose is only to double check the search strategy.

What is my purpose?  To see if all the documents that I want to find were found. So I need to go through all those that didn't make the cut to see any parameters I need to change. A new code for those called Lex-MISS

eek! working in backup and know I can't save as... Repeat.

OK have the set re-created, now will work through all uncoded documents searching for educ* in both abstract and PDF. All documents that "should" have been picked up will be coded with Lex-MISS. Sorted by name because sometimes that turns out to be helpful. Immediately helpful because at least the Folder (which contains both RIS and PDF) and author / year are easy to compare.

Start 20191128 20:20
Tried Export Components to Project Files produced a detailed xlsx - I wanted the document titles to keep a record as I checked. Sheet "Coded Segments" column C contained the Code, separating those in the "Other" folder from the Lex-search files. This was accidental but useful.

 Problem was that when I filtered the documents to only show "other", I couldn't then subtotal them on the same page. Remove subtotoals.aha! remembered there's a conditional formatting that colours duplicates. then can I sort by colour? Way too much data, slow to manipulate. Can I export Sets as part of the document system? Nope, not included in the xport/. OK, links export should pick up one document per PDF if I get links just for th ePDFs. Realise it's easier to split into PDF not found and RIS not found, RIS will have extra links like URLs in them.

 Go back to Data Editor - all documents. click by hand NO on everything that's not PDF or RIS. Then I want to repeat the search but without "Psychology" as a stop word and see if I get a comparable list.

 OK Exported variables out to Excel. Use filters to identify documents with 0 in RIS or PDF variable and add a 1 into NO. Tested and 26 found with 1 in PDF and 6 in RIS so correct set. SORT so selection is easier. Reimported. It added some new RIS-specific fields, but looks like it worked to set NO to 1. I changed the variable name to indicate that it denotes those works not found by the first pass of searching.

 Going back and double-checking this document, there were 362 records, one of which will have been the duplicate PDF. So the 361 00 is correct. On checking, I found 32 records that weren't in any of the three sets (my manual intervention clearly failed.) I did this in Excel, but how should I do i in 2020? [now finds 7 RIS, still 26 PDF, NOTIDd1 301; there are 393 named documents]

 Used mixed methods activate by variable with all three AND=0; there are the 60 documents, all EN except one; the PDF uncoded, EN coded. Go to Analysis, summary grid with EN activated to see if any had been "set" coded NOPE none. I think this was just error on my part, still not sure about the odd number of records. But now will code that unfound set and it should then be empty. Not quite accurate to say missed here, but investigation worthwhile and so was review.



 | Set                                    | Parameters                                                                                                                 | Number |
 |----------------------------------------|----------------------------------------------------------------------------------------------------------------------------|--------|
 | Lex-search-NOTIDd1=1                   | Should be identical, as I added the NOT variable manually                                                                  | 300    |
 | Lex-search-PDFs=0 AND Lex-search-RIS=0 | All documents that did not have either variable = 1 (that is, those not found in the first pass over RIS and PDF documents | 361    |

#### What accounts for the difference?
Export both sets of variables to Excel: /Volumes/eb/Dropbox/Documents/-Fed/Termites-and-Butterflies/Data/RepPlus-Doc-Set-Variables-Compare.xlsx

Sort by RIS_Title, Conditional formatting, format unique values green (those without matching PDF or RIS), then filter by cell colour. 31 unique values in PDF/RIS; 80 unique in the NotIDd1. maybe I need to combine the sheets and then check?


 Now I will re-run the search without psychology in the stop words. It's not there already!

 patient
 patients
 medication
 medicine
 medicines
 clinical
 clinician
 depression
 surgery
 therapy
 psychosis
 psychoses
 disease
 pgi
 schizophrenia
 clinic
 chronic
 med
 nr
 recovery
 depression
 trial
 counsel
 counselling
 child
 children

Difficult to know what's ruling it out so I am going to hand check all the NOTIDd1 and code them, Keeping an eye on what the stoppers are, or whether it's accurate.
I can code with MISS those that should have been found and run a lexical analysis on them.
I can code with anothe NO those that were rightly ignored.
Then I can compare with the Variables-Mod sheet if I think I've missed anything.

When NO coding, selecting enough of the document to make it clear why not.
If MISS and NO together, means should have been picked up for the term but is not relevant to education context. [this not really rigid - be more specific]

Decided the feedback trainer papers that are technical are not included. Many of the Gaines papers were about training feedback systems to train control techs, or generally about the usefulness of computers in Ed. Not RepGrid.Mostly also perceptual motor skills, can group by that on another pass. "human controller" search should get all these.human adaptive controller, feedback training, learning machine,

Realised that the MISSs so far have been Ed but not RepGrid. Reclassify NO to No RepGrid no Ed and MISS to only those with both.

Searching documents by hand for these terms.

Those rightly ignored coded as NO.

So. Those that were not found before, but which contained "educa*" AND "grid" weren't found in some cases because the search parameters specified "repgrid" or "repertory grid".

How do I find them in 2020?
They will all be coded with MISS. Turns out I coded them NotIDd1. Is that bad? It will depend if any of the NO also have this code because they are in the set that wasn't found. Don't think it's a problem.

| Code               | Definition                                                                                                                                                                                                                                                                   |
|--------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Lex-search-NO      | does not meet query parameters including having "repertory grid" OR repgrid AND educa*on first pass AND after manual review                                                                                                                                                  |
| Lex-search-NOTIDd1 | not found in RIS or PDFs but DOES meet SOME query parameters including having educa* and "grid" but some have repertory grid or repgrid, so must have stopwords, while others have webgrid or other *grid - manual search was for grid to see extent of this potential issue |
| Lex-search-RIS     | met query parameters on first pass in EN record                                                                                                                                                                                                                              |
| Lex-search-PDFs    | met query parameters on first pass in PDF record                                                                                                                                                                                                                             |

still a bit shaky on these numbers.

realised I am getting codes and variables confused - I had converted the previous codes to variables but not the most recent. Decided just to do the NO as there will only be one of those for each document (one per RIS one per PDF)- can be binarised as before anyway.

1. co to code system
1. select code
1. right click -> transform to document variable
1. select document system
1. Variables menu -> list of document Variables
1. Click the variable, then command-B or the little 101 button to convert


### Analyse these results - how reliable are they for larger data review?
1. Select set
1. Activate all Documents
1. Analysis tab

It left the original coding intact.



---
so now I'm ready to tidy things up a bit...
Records searched (separate EN and PDF)
Overlap in ES is one more EN than PDF. 63rd gaines 1976
it is because PDF is unavailable:
RPRT
Some notes on the provision of data acquisition, processing and retrieval in the small EDP environment.
Gaines, B. R.
1976
Colchester, UK
Department of Electrical Engineering Science, University of Essex
Whilst the conventional image of EDP computer is as a 'number cruncher' providing large-scale computational resources for a high throughput of numerical calculations, there are an increasing number of small EDP applications whose requirements are primarily those of accurate data acquisition, communication, storage and retrieval, rather than calculation. Even the classical database computations of search, sort and merge, are not dominant in these applications since the prime requirement is simple storage rather than global analysis.
 (Gaines, B. R. - 1976 , Pos. 1-7)
---

back to excel for the summing up


Searched 196 from RepPlus site, I need to know which of those are not NO.

Mixed methods tab -> activate documents by variables - Lex-search-NO =1 -> New set -> sort by name, then manuall highlight PDF? there isn't a document type variable. Well PDF is a variable in the Lex-search-PDF found set, and then I could manually remove the NOTIDd1?

I will do two sets for now.
Lex-search-PDFs=1 = *29 Documents*

and

Lex-search-NOTIDd1=1 AND Lex-search-NO=0 AND Lex-search-PDFs=0
1 removed "grid" only, related to computer programming - hyperverse
1 removed no "grid" at all: Shaw-1979-Personal learning through the comput.pdf (Shaw, M. L. G. - 1979 , Pos. 8) no grid but it is about SOCIOGRIDS and so relevant
Problem with NotIDd1 being both variable and code is that if incorrect can't redo variable easily.

So just for this messy group I will add another code that tells me if it should be yes or should be NO.

SBF - shuld have been found -> educa* & repgrid 'repertory grid' then check stopwords
NFB - should not have been found but know it's relevant.

working htrough set *Lex-search-NOTIDd1=1 AND Lex-search-NO=0* so not found, and not dismissed in the first review

every document in the set should end up with  one of these or a NO.
NO prob won't help so also doing NO review 2

DONE.

Time to consolidate project across computers and do some separation of method from methodology here.

28 Documents







There were x many of these.

Others which did have "repertory grid" & "educa*" must have had stopwords in the them.

There were x of these.
The stopwords most occurring were

This allows me to refine the next, larger, search.

Lots of modelling = coded for later
Look up semantic networks later
Lots of foundational CSCL
Looks like those that were missed had "grid" with a prefix other than rep
"knowledge representation"
"concept maps"
"knowledge acquisition"
"knowledge maps"
Collabor*
agents
rules

peer for PR
intervention for PR



Coding modelling even if no RepGrid for post-review.

To go to the document that a memo is in from the overview, click the row and the document or code will be higlighted in the browser.


## library hell below

at Library today thinking I should apply same search strategies to books & book chapters. how can I get all those stop words into my library search? I'll paste them in one by one. Can only have four paramters. test which are the most effective. With frist four terms, >8000 results.

Limiters are definitely not working, chose sixth down in list at random and a keyword is psychotherapy, which should have been caught by my psycho* NOT. Try psychotherapy in full. It is still in the list. Updated search parameters from Any Field to Subject. No effect.

OK new approach is all those, plus filter subject to only include Repertory Grid Technique, Repertory Grid, Education, Repertory Grid Method, Higher Education. only 2943 results, but still including psychotherapy results. Will have to filter by keyword in 2020 using stopwords there. How doI get the ris out of the Library?

https://sydney.primo.exlibrisgroup.com/discovery/search?query=any,contains,%22repertory%20grid%22,OR&query=any,contains,repgrid,AND&query=sub,contains,education,NOT&query=sub,contains,patient*,NOT&query=sub,contains,psychotherapy,NOT&query=sub,contains,clinic*,NOT&query=sub,contains,counsel*,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=date_a&vid=61USYD_INST:sydney&mfacet=topic,include,Repertory%20Grid%20Technique,1&mfacet=topic,include,Repertory%20Grid,1&mfacet=topic,include,Education,1&mfacet=topic,include,Repertory%20Grid%20Method,1&mfacet=topic,include,Higher%20Education,1&lang=en&mode=advanced&offset=0&pcAvailability=true&came_from=sort

##same search from home resulted in 2935 results!

Search parameters are at /Users/eb/Desktop/Screen Recording 2019-12-03 at 8.06.14 pm.mov
So, 50 max export and no way to limit to books and chapters.
Let's party

stuck on this page https://sydney.primo.exlibrisgroup.com/discovery/search?query=any,contains,%22repertory%20grid%22,OR&query=any,contains,repgrid,AND&query=sub,contains,education,NOT&query=sub,contains,patient*,NOT&query=sub,contains,psychotherapy,NOT&query=sub,contains,clinic*,NOT&query=sub,contains,counsel*,AND&tab=Everything&search_scope=MyInst_and_CI&sortby=date_a&vid=61USYD_INST:sydney&mfacet=topic,include,Repertory%20Grid%20Technique,1&mfacet=topic,include,Repertory%20Grid,1&mfacet=topic,include,Education,1&mfacet=topic,include,Repertory%20Grid%20Method,1&mfacet=topic,include,Higher%20Education,1&lang=en&mode=advanced&offset=900&pcAvailability=true&came_from=sort
only loading 900 to 920. reset

so now the search is only showing 1195 Results
and it;s changed the year dates
when i go back and manually remove the dates I get 2395 results again


trying FF
nightmare emailed support again - nobody there today on chat or phone and no reply.

Tried search this afternoon from home logged in and 1147 results Screen Shot 2019-12-04 at 5.30.45 pm.png

Give up and go back to RepPlus.















(This is a note to myself to table up the participants in the studies - low numbers?)



---
What are the advantages of a ssr?

What do examples of SSR look like?
-

Why?

RepGrid is not effectively operationalised {McKellar, 2014 #1} in educational contexts where it could be of value.

The search should be inclusive {McKellar, 2014 #1}








Remember to go back later on an merge the semi-dup RIS variables.



So I'm bringing the files into 2020 for ths scoping review because it allows me to use machine anlaysis as well as my own views to identify relevant materials.
