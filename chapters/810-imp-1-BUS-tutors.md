## Comparing an individual model where elements have been categorised to an expert model.

The University of Sydney&#39;s Business School has one of the largest cohorts of international students in Australia. As well as the domain content, many of these students are also learning academic English by trial an error. The Business School supports students by offering a diagnostic test on entry, a short written tasks which is then marked according to an established rubric. For the past decade, these tests have been done under face-to-face exam conditions hard-copy paper. In the current COVID-19 environment, this will no longer be viable. In considering how this diagnostic might be moved online in a way that provided additional information for both staff and students, it was identified that a pilot Repertory Grid Technique exercise with a very small but typical cohort could be a useful test of the method&#39;s utility.

Previous written tasks are used as the elements, with the constructs being a set of standard ratings from a High Pass (9) to Fail (1) or no attempt.

In this pilot, we first scanned the examples of work that the tutors would assess as a calibration exercise. In the past, this has been done with PowerPoint video, and it has been effective and useful. The advantage here of using the WebGrid package is that tutors can compare their own ratings with the &quot;expert&quot; model, and models of other tutors.

First the examples were added as elements A to H. Each element has an annotation containing a hyperlink to the example as an image file (eg \&lt;p\&gt;\&lt;a href=&quot;http://ech08ravo.com/wp-content/uploads/2020/07/Example00009.png&quot; \&gt;Show Example 9\&lt;/a\&gt;\&lt;/p\&gt;). This allows respondents to click the link to view the different examples that are the subject of the inquiry.

In the Options pane, select &quot;Category&quot; as the data type. Then when you proceed, you&#39;ll be presented with a triad, as in Figure [F] below.

![](RackMultipart20200829-4-m66ekj_html_6f23809123b3e1f2.png) click Add construct to add the category, and you&#39;ll then be asked to rate all elements on that category.

![](RackMultipart20200829-4-m66ekj_html_340a7e7528bee576.png)

Enter the construct name, and add a weight (which is equal to adding that construct multiple times) or level (specifying a construct as an &#39;output&#39; or giving it a &#39;level&#39; relative to other constructs

are provided to support algorithms for modelling the conceptual structure) if that is desired. Click the Output button to expect output. click Done, and then add the next construct. After adding the next construct I clicked cancel instead of categorising the elements, and then added the third category. Neither worked this wayl; when I got back to the main page there was only one so I manually added them in again. Then when I clicked done instead of rating them I got the unspecified ratings again.

**\*\*potential for confusion if the numbers don&#39;t match the direction of the grading – doesn&#39;t make sense for the FAIL-1 to have a 5 beside it\*\* so enter them upward rather than downward – can edit after entry.**

When you differentiate the triad, it seems like you are assigning the pole rating to the element but you aren&#39;t, just setting the dimension.

SAVE locally before caching in case of cache failure. Then, [exchange](http://10.83.67.230/WebGrid/Exchange/Cache/0050569DCA3EFC83182A4/0050569DCA3EFC83AEE8E.rgrid??+C)the grid, it will go through name and elicitation process BUT the format does not allow links to the elements if you just click &quot;add construct&quot;. When I tried to fix it I now have 27 unspecified items. The plot display showed everything at &quot;4&quot;, so I clicked &#39;update&#39; to reload and re-check &quot;use in plots&quot; and &quot;output&quot; for each category. That seemed to work. OK. now I need an empty version and an expert version.

![](RackMultipart20200829-4-m66ekj_html_eb0ffa80ee79ca02.png)

Issue is that the link only shows in the elicit a new construct dialog, not the categorisation. Looks like the only options are as a raw URL in the element name OR stuff in the category annotation. I think it belongs more naturally in the element name but it&#39;s something it would be good to fix.

Difficult to decide on image or PDF for linked document examples. Both have advantages but behaviour will not be consistent across platforms. The inline option still needs to work somehow.

solution? add in to the customisation layer.

![](RackMultipart20200829-4-m66ekj_html_d3439cf74c2e2e2c.png)

OK, have updated Header insert to change styles, updated the element titles and added linked thumbnails in the Body Insert field.

![](RackMultipart20200829-4-m66ekj_html_a272fd16c09a7f38.png)

Now I want to hide everything that BUS don&#39;t need to see. But first I need to demonstrate the &quot;compare&quot;.

New cache for demo with prev credentials: [http://10.83.67.230/WebGrid/Cache/0050569DCA3EFC84EFE5B](http://10.83.67.230/WebGrid/Cache/0050569DCA3EFC84EFE5B)

Link to exchange grid: [http://10.83.67.230/WebGrid/Exchange/Cache/0050569DCA3EFC84EFE5B/0050569DCA3EFC850A745.rgrid??+C](http://10.83.67.230/WebGrid/Exchange/Cache/0050569DCA3EFC84EFE5B/0050569DCA3EFC850A745.rgrid??+C)

Let&#39;s say expert has the pattern above, then for Structure and Argument adjust randomly one up or down for at least two per category until we get a proper expert model.

OK. remediation process which I use a lot is

Save both download and in &quot;junk&quot; cache

Then load the grid

Edit the elements/constructs

Save both download and in &quot;junk&quot; cache

Click exchange grid link and check if all is fixed

Add expert model data entry

Save both download and in the central or each participant&#39;s cache (create these first duh)

Go to participant or central cache (there is a link on the page after you save it)

Haven&#39;t adjusted style sheet for that yet

![](RackMultipart20200829-4-m66ekj_html_8e024c569df5bf07.png)

Let&#39;s say I have created a cache for Tutor Bob :

**Your Cache Directory,**  **0050569DCA3EFC8517C2B**** , has been Registered**

You may cache a grid in it using the &quot;Save/Exchange&quot; button in WebGrid.

You may view, manage, analyze and use your cached grids through the URL

[**http://10.83.67.230/WebGrid/Cache/0050569DCA3EFC8517C2B**](http://10.83.67.230/WebGrid/Cache/0050569DCA3EFC8517C2B)

I load the cache

![](RackMultipart20200829-4-m66ekj_html_5a3fdf05fde48815.png)

Then click the upload button and upload my expert model

![](RackMultipart20200829-4-m66ekj_html_10994ad2a0ba573f.png)

it will be visible when you refresh the cache

![](RackMultipart20200829-4-m66ekj_html_fbfadfde9aa7cd07.png)

Click the exchange A button

It will load a page whose URL you provide to the participant, eg
[http://10.83.67.230/WebGrid/Exchange/Cache/0050569DCA3EFC84EFE5B/0050569DCA3EFC850A745.rgrid??+C](http://10.83.67.230/WebGrid/Exchange/Cache/0050569DCA3EFC84EFE5B/0050569DCA3EFC850A745.rgrid??+C)

![](RackMultipart20200829-4-m66ekj_html_ae35162a422b2870.png)

tutor bob starts the grid process

![](RackMultipart20200829-4-m66ekj_html_90e8f0de8582beed.png)

clicking the title or thumbnail displays the text (at the moment an image) in a new window – so they can have all of them open at once (so we need to add a heading to each one so they know which it is).

![](RackMultipart20200829-4-m66ekj_html_52627b01b0112beb.png)

They go ahead and assign categories (I have just put random ratings in here for illustration as tutor bob).

First Thesis (or whatever), then click Done

![](RackMultipart20200829-4-m66ekj_html_9d97a435912ed059.png)

and again for the other criteria…

![](RackMultipart20200829-4-m66ekj_html_eab78104c74e3240.png)

After the three are done, the participant will return to the main page

![](RackMultipart20200829-4-m66ekj_html_a6993a065697a836.png)

[hiding the other bits are what I&#39;m working on at the moment]

they should click &#39;Save&#39;

Save both download and in their tutor bob cache **0050569DCA3EFC8517C2B**

![](RackMultipart20200829-4-m66ekj_html_f110ba8e18b99abe.png)

Cache in directory.

![](RackMultipart20200829-4-m66ekj_html_48ba54446865174a.png) Then, tutor bob clicks the link to access her cache directory.

![](RackMultipart20200829-4-m66ekj_html_f42b41a8112bcbd9.png)

Leave the expert model at A, click the B radio button next to tutor bob, then click Compare.

![](RackMultipart20200829-4-m66ekj_html_22bc211ef0f46d1c.png) (another style sheet to fix).

In the manual, this representation is described:

_When two grids were elicited from the same person or from two members of the same community who are expected to use similar terminology to identify events and shared concepts, if they have have elements and/or constructs in common it is possible to be able to compare them for similarities and differences in the use of constructs and the construing of elements. The &#39;Compare&#39; tool in RepGrid provides a graphic comparison of such grids based on the MINUS algorithm of Shaw (1980) extended to grids having a diversity of rating scales including multiple types. Note that determining common elements across grids is based on lexical equality of the element names, and common constructs on the lexical equality of the pole names and construct names (if any). Hence a grid being compared should not have two or more elements with the same name or two or more constructs that are equal on the above criterion. The supposition that lexically equivalent elements and/or constructs are intended by the elicitee(s) to have &#39;the same meaning&#39; needs careful consideration and justification if the analysis is to be meaningful. This is usually addressed by preliminary discussions with the elicitees or a focus group representing them or managing the study._

The stuff in yellow being precisely the point of doing it!

What the comparison shows is the difference in rating between the expert and the tutor bob ratings for each element on each category/construct. There are other options and representations using the standalone application but for now this is probably OK. It will compare Grid A with Grid B based on radio buttons above, but this can be reversed.

The matrix shows the absolute difference between scores with the constructs and elements sorted so that those that are most similar in the two grids are the top and on the right, respectively (although it says left on p 84 of the manual, this is not the case using the WebGrid cache AFAICS.

![](RackMultipart20200829-4-m66ekj_html_3723528c6392393e.png)

So what we can see above is that tutor bob&#39;s ratings are identical for example F, only slightly different for Example H, etc. and we can also see that there is a big difference in ratings on Example D on the Argument/critical thinking dimension.

Would you like to give this a go and let me know what you think?

Warning! If your cache does not exist, when you attempt to save your file you will lose all data! It&#39;s always worth downloading the file locally

BLACK 199608077 Thesis v1 RackMultipart20200829-4-m66ekj.docx2 of 2
